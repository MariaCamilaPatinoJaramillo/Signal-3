{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Miniproyecto_entrega.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO3wMYDaJ2UrgDpMTwmJjnL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MariaCamilaPatinoJaramillo/Signal-3/blob/main/Miniproyecto_entrega.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Miniproyecto 1 analisis de señales EMG y extraccion de caracteristicas \n",
        "\n",
        "* **Jesus David Restrepo Martinez**\n",
        "\n",
        "* **Daniel Arturo Vega Hernandez**\n",
        "\n",
        "* **Maria Camila Patiño Jaramillo**\n",
        "\n",
        "**Tratamiento de Señales III**\n",
        "\n",
        "*Universidad de Antioquia*\n",
        "\n",
        "*Prof. Hernán Felipe García Arias, PhD*\n",
        "\n",
        "2021-2"
      ],
      "metadata": {
        "id": "lS35cpMQsR3u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Primera parte para la extraccion de caracteristicas y creacion de la matriz para la señal completa \n"
      ],
      "metadata": {
        "id": "bnBIWG2wpqYP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eiTgDoD9wFKs",
        "outputId": "fd58af17-dcf1-4d59-9289-2fe6578083ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.io import loadmat\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import signal"
      ],
      "metadata": {
        "id": "PnA4_8G2XgBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ruta = '/content/drive/MyDrive/Miniproyecto-Señales3/'\n",
        "data = loadmat(ruta+'S1_20140620T021349.mat')"
      ],
      "metadata": {
        "id": "JFuAC8dPXSfZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ruta = '/content/drive/MyDrive/Miniproyecto-Señales3/'\n",
        "data = loadmat(ruta+'S2_20140623T203911.mat')"
      ],
      "metadata": {
        "id": "nzyoMTG2ZOmr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ruta = '/content/drive/MyDrive/Miniproyecto-Señales3/'\n",
        "data = loadmat(ruta+'S3_20140623T192807.mat')"
      ],
      "metadata": {
        "id": "VmSPOI05ZOXp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Llave para acceder al diccionario y obtener los datos correspondientes a EMG\n",
        "print('Keys: ',data.keys())\n",
        "\n",
        "data_EMG = data['data_EMG']\n",
        "fs = 4e3\n",
        "Ts = 1./fs\n",
        "\n",
        "print('N (length),\\t N_Class\\t Trials: ',np.shape(data_EMG) )\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AyFVsxc_ZP7Y",
        "outputId": "db479de4-2f39-4d83-da81-054506600c16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keys:  dict_keys(['__header__', '__version__', '__globals__', 'data_ACC', 'data_EMG'])\n",
            "N (length),\t N_Class\t Trials:  (20000, 6, 189)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def featureExtractionEMG(sampleSignal):\n",
        "  # Esta función toma como argumento de entrada una señal EMG de 20000 muestras y retorna 13 caracteristicas relacionadas a la señal\n",
        "  # a. Removemos el nivel DC\n",
        "  nivelDC = np.mean(sampleSignal)\n",
        "  sampleSignal = sampleSignal-nivelDC\n",
        "  # b. Normalicemos las señales para que tengan amplitud unitaria\n",
        "  maxSignal = np.abs(np.max(sampleSignal))\n",
        "  sampleSignal = sampleSignal/maxSignal\n",
        "  # Realicemos el análisis STFT\n",
        "  f, t, Zxx = signal.stft(sampleSignal, fs, nperseg=600)\n",
        "\n",
        "  rms = np.sqrt((np.sum(sampleSignal)**2)/len(sampleSignal))\n",
        "  mae = np.sum(np.abs(sampleSignal))/len(sampleSignal)\n",
        "  # En la matriz Zxx se tiene una matriz de #defrecs * #times\n",
        "# Zxx[i,j], sería el espectro en la frecuencia[i] y el tiempo [j]\n",
        "  absZxx = np.abs(Zxx)\n",
        "  Pmax_Zxx = np.max(absZxx,axis=1) # dB\n",
        "\n",
        "#Para calcular los cruces por cero\n",
        "  i=0\n",
        "  cont=0\n",
        "  for n in range (0,(len(sampleSignal)-1)):\n",
        "    if( (sampleSignal[n]>0 and sampleSignal[n+1]<0) or (sampleSignal[n]<0 and sampleSignal[n+1]>0)):\n",
        "      cont=i+1\n",
        "      i=i+1\n",
        "    else:\n",
        "      cont=i+0\n",
        "\n",
        "  Pmax_Zxx_dB = 20*np.log10(Pmax_Zxx)\n",
        "  idx = np.argsort(Pmax_Zxx_dB)\n",
        "  maximos = Pmax_Zxx_dB[idx]\n",
        "  auxPot = maximos[-5:]\n",
        "  frecuencias = f[idx]\n",
        "  fPmax_Zxx = frecuencias[-5:]\n",
        "  feature_set = np.zeros((13,))\n",
        "  feature_set[0] = rms\n",
        "  feature_set[1] = mae\n",
        "  feature_set[2:7] = auxPot\n",
        "  feature_set[7:12] = fPmax_Zxx\n",
        "  feature_set[12]=cont\n",
        "  # To do : calcular el número de cruces por cero\n",
        "  return feature_set"
      ],
      "metadata": {
        "id": "8LKps-BFmWQI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Las dimensiones de data EMG corresponden a 20000,6,189 donde:\n",
        "#20000 corresponde a los datos\n",
        "# 6 el tipo de movimiento\n",
        "# 189 el numero de intentos por ese movimiento \n",
        "\n",
        "#lo que se esta haciendo es crear la matriz de caracteristicas para toda la señal x y tambien se crea un vector columna que representa el tipo de movimiento T\n",
        "L_Signal, Classes, Ntrials = np.shape(data_EMG)\n",
        "D = 13 # número de características\n",
        "\n",
        "X = np.zeros((Classes*Ntrials,D))\n",
        "t = np.zeros((Classes*Ntrials,1))\n",
        "pos = 0\n",
        "for clase in range(0,Classes):\n",
        "  for n in range(0,Ntrials):\n",
        "    sampleSignal = data_EMG[:,clase,n]\n",
        "    # Luego le extraemos las D características a cada señal del experimento\n",
        "    x_n = featureExtractionEMG(sampleSignal)\n",
        "    X[pos, :] = x_n\n",
        "    t[pos] = clase\n",
        "    pos = pos + 1"
      ],
      "metadata": {
        "id": "QR_sJ1NVmGS5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Aqui ya tenemos la señal original con todas las caracteristicas que serian 13 \n",
        "\n",
        "print(np.shape(X))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JwD_I1_wnHLo",
        "outputId": "900892e2-1ecd-4db6-8cc4-7ef6982cf5af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1134, 13)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Segunda parte usando las funciones de wavelet, extraccion de caracteristicas y formacion matriz gigante"
      ],
      "metadata": {
        "id": "M6XI1xM4p36_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pywt  #nombre de la libreria \n",
        "import pywt\n",
        "import numpy as np\n",
        "data =sampleSignal\n",
        "np.shape(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhPRhoEJqDdO",
        "outputId": "98e1cc01-d655-4c5e-cb81-e46188138dc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20000,)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para la parte de las funciones wavelet se va a crear una matriz que va a tener \n",
        "+ N filas : que corresponden a los niveles de descomposicion \n",
        "+ 2 columnas: donde una van a ser los coeficientes de aproximacion(Pasaaltas) y la otra los coeficientes de detalle (Pasabajas)  "
      ],
      "metadata": {
        "id": "B8F5U65KrKmY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy \n",
        "from scipy.stats import entropy\n",
        "\n",
        "def calculate_entropy(list_values):\n",
        "  value,counter_values = np.unique(list_values, return_counts=True)\n",
        "  entropyVal = entropy(counter_values, base=None)\n",
        "  return entropyVal\n",
        "\n",
        "def calculate_statistics(list_values):\n",
        "  n5 = np.nanpercentile(list_values, 5)\n",
        "  n25 = np.nanpercentile(list_values, 25)\n",
        "  n75 = np.nanpercentile(list_values, 75)\n",
        "  n95 = np.nanpercentile(list_values, 95)\n",
        "  median = np.nanpercentile(list_values, 50)\n",
        "  mean = np.nanmean(list_values)\n",
        "  std = np.nanstd(list_values)\n",
        "  var = np.nanvar(list_values)\n",
        "  rms = np.nanmean(np.sqrt(list_values**2))\n",
        "  return [n5, n25, n75, n95, median, mean, std, var, rms]\n",
        "\n",
        "def calculate_crossings(list_values):\n",
        "  zero_crossing_indices = np.where(np.diff(np.signbit(list_values)))[0]\n",
        "  no_zero_crossings = len(zero_crossing_indices)\n",
        "  mean_crossing_indices = np.where(np.diff(np.signbit(list_values-np.nanmean(list_values))))[0]\n",
        "  no_mean_crossings = len(mean_crossing_indices)\n",
        "  return [no_zero_crossings, no_mean_crossings]\n",
        "\n",
        "def get_features(list_values):\n",
        "  entropy = calculate_entropy(list_values)\n",
        "  crossings = calculate_crossings(list_values)\n",
        "  statistics = calculate_statistics(list_values)\n",
        "  return [entropy] + crossings + statistics"
      ],
      "metadata": {
        "id": "tqvUd418-bk4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PARA LA DESCOMPOSICION #1 "
      ],
      "metadata": {
        "id": "yjlltlWVsQd_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pywt\n",
        "import numpy as np\n",
        "import sys\n",
        "\n",
        "\n",
        "X_1 = np.zeros((Classes*Ntrials,12))\n",
        "X_1_1 = np.zeros((Classes*Ntrials,12))\n",
        "t_1 = np.zeros((Classes*Ntrials,1))\n",
        "pos=0\n",
        "bu=[]\n",
        "for clase in range(0,Classes):\n",
        "  for n in range(0,Ntrials):\n",
        "    signal = data_EMG[:,clase,n]\n",
        "     \n",
        "    nDesc =1\n",
        "    waveletname = 'db'+str(nDesc)\n",
        "\n",
        "    for i in range(nDesc):\n",
        "      (data, coeff_d) = pywt.dwt(signal, waveletname)\n",
        "      conjunto1Features1 = get_features(data)\n",
        "      conjunto1Features1_1 = get_features(coeff_d)\n",
        "      X_1[pos, :] = conjunto1Features1\n",
        "      X_1_1[pos,:]=conjunto1Features1_1\n",
        "      t[pos] = clase\n",
        "      pos = pos + 1\n",
        "\n",
        "data_des1=data\n",
        "\n",
        "  \n"
      ],
      "metadata": {
        "id": "4lrM8ZNCtZcg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "print(len(data_des1))\n",
        "print(conjunto1Features1)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4Aj1Ueo24Y-",
        "outputId": "26fa2b92-a745-48af-b310-711025f17011"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10000\n",
            "[9.049483859312355, 756, 754, -0.19479777805461843, -0.07223498375967644, 0.08566301517303607, 0.19681948982404826, 0.007760466996277807, 0.004932234917830498, 0.1361759163469834, 0.018543880192940617, 0.09847764520505319]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Para la descomposicion #2"
      ],
      "metadata": {
        "id": "5aSoO9NLsn_f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pywt\n",
        "import numpy as np\n",
        "import sys\n",
        "\n",
        "señal2=np.zeros((len(data_des1),Classes,Ntrials))\n",
        "for z in range(0,len(data_des1)):\n",
        "  for clase in range(0,Classes):\n",
        "    for n in range(0,Ntrials):\n",
        "    \n",
        "      señal2[z,clase,n]=data_des1[z]\n",
        "\n",
        "X_2 = np.zeros((Classes*Ntrials,12))\n",
        "t_1 = np.zeros((Classes*Ntrials,1))\n",
        "pos=0\n",
        "data_des2=[]\n",
        "for clase in range(0,Classes):\n",
        "  for n in range(0,Ntrials):\n",
        "    signal1 = señal2[:,clase,n]\n",
        "     \n",
        "    nDesc =1\n",
        "    waveletname = 'db'+str(nDesc)\n",
        "\n",
        "    for i in range(nDesc):\n",
        "      (data1, coeff_d) = pywt.dwt(signal1, waveletname)\n",
        "      conjunto1Features2 = get_features(data1)\n",
        "      X_2[pos, :] = conjunto1Features2\n",
        "      t[pos] = clase\n",
        "      pos = pos + 1\n",
        "    \n",
        "  data_des2=data1"
      ],
      "metadata": {
        "id": "jOs6jaZAkVsD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Descomposicion #3"
      ],
      "metadata": {
        "id": "DKq-gatst4jB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pywt\n",
        "import numpy as np\n",
        "import sys\n",
        "\n",
        "señal3=np.zeros((len(data_des2),Classes,Ntrials))\n",
        "for z in range(0,len(data_des2)):\n",
        "  for clase in range(0,Classes):\n",
        "    for n in range(0,Ntrials):\n",
        "    \n",
        "      señal3[z,clase,n]=data_des2[z]\n",
        "\n",
        "X_3 = np.zeros((Classes*Ntrials,12))\n",
        "t_1 = np.zeros((Classes*Ntrials,1))\n",
        "pos=0\n",
        "data_des3=[]\n",
        "for clase in range(0,Classes):\n",
        "  for n in range(0,Ntrials):\n",
        "    signal2 = señal3[:,clase,n]\n",
        "     \n",
        "    nDesc =1\n",
        "    waveletname = 'db'+str(nDesc)\n",
        "\n",
        "    for i in range(nDesc):\n",
        "      (data2, coeff_d) = pywt.dwt(signal2, waveletname)\n",
        "      conjunto1Features3 = get_features(data)\n",
        "      X_3[pos, :] = conjunto1Features3\n",
        "      t[pos] = clase\n",
        "      pos = pos + 1\n",
        "    \n",
        "  data_des3=data2\n"
      ],
      "metadata": {
        "id": "TslpXVN7p3vN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ya se tienen la matriz de caracteristicas para las 3 descomposiciones de la funciones wavelet"
      ],
      "metadata": {
        "id": "iQh-CQVewWc6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.shape(X))  #vector de caracteristicas de la señal original\n",
        "print(np.shape(X_1_1)) # vector de caracteristicas para la primera descomposicion de los coef de pasa altas\n",
        "print(np.shape(X_1)) # vector de caracteristicas para la primera descomposicion\n",
        "print(np.shape(X_2))  # vector de caracteristicas para la segunda descomposicion\n",
        "print(np.shape(X_3))  # vector de caracteristicas para la tercera descomposicion"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZTv4WhGv_or",
        "outputId": "1b7313af-542a-4731-db88-9c8dbbdf0e20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1134, 13)\n",
            "(1134, 12)\n",
            "(1134, 12)\n",
            "(1134, 12)\n",
            "(1134, 12)\n"
          ]
        }
      ]
    }
  ]
}